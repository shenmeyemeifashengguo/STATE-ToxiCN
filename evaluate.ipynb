{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2157\n",
      "Recall: 0.2104\n",
      "F1 Score: 0.2130\n"
     ]
    }
   ],
   "source": [
    "# Quadruple Hard Matching\n",
    "\n",
    "import json\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted quadruples\n",
    "    predicted_positives = 0  # Predicted positives: Total number of quadruples predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of quadruples in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "\n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            for t in target_quadruples:\n",
    "                if pred == t:  # If predicted quadruple exactly matches target quadruple\n",
    "                    true_positives += 1\n",
    "                    target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                    break  # Exit inner loop once a match is found\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.4415\n",
      "Recall: 0.4307\n",
      "F1 Score: 0.4360\n"
     ]
    }
   ],
   "source": [
    "# Quadruple Soft Matching\n",
    "\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Calculate precision, recall, and F1 score (soft matching)\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions (soft matching)\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted quadruples\n",
    "    predicted_positives = 0  # Predicted positives: Total number of quadruples predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of quadruples in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "        \n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            target_parts = None\n",
    "            \n",
    "            matched = False  # Flag to indicate if a matching target quadruple is found\n",
    "            \n",
    "            # Find matching target quadruple\n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    target_entity, target_speech, target_group, target_hate = target_parts\n",
    "                    pred_entity, pred_speech, pred_group, pred_hate = pred_parts\n",
    "                    \n",
    "                    # Use soft matching for the first two components\n",
    "                    similarity = SequenceMatcher(None, target_entity, pred_entity).ratio()\n",
    "                    similarity_speech = SequenceMatcher(None, target_speech, pred_speech).ratio()\n",
    "                    \n",
    "                    # If similarity for first two components is >= 0.5 and last two components match exactly\n",
    "                    if similarity >= 0.5 and similarity_speech >= 0.5 and target_group == pred_group and target_hate == pred_hate:\n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        matched = True  # Mark as matched\n",
    "                        break  # Exit inner loop and move to next predicted quadruple\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "# Run main function\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2592\n",
      "Recall: 0.2529\n",
      "F1 Score: 0.2560\n"
     ]
    }
   ],
   "source": [
    "# Triple Hard Matching\n",
    "import json\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted quadruples\n",
    "    predicted_positives = 0  # Predicted positives: Total number of quadruples predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of quadruples in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "\n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            \n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # Ensure the number of elements in quadruples is correct, then compare the first two and last elements\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    target_entity, target_speech, _, target_hate = target_parts\n",
    "                    pred_entity, pred_speech, _, pred_hate = pred_parts\n",
    "                    \n",
    "                    # If the first two elements and the last element are identical, consider it a match\n",
    "                    if (target_entity == pred_entity and \n",
    "                        target_speech == pred_speech and\n",
    "                        target_hate == pred_hate):\n",
    "                        \n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        break  # Exit inner loop once a match is found\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5234\n",
      "Recall: 0.5106\n",
      "F1 Score: 0.5169\n"
     ]
    }
   ],
   "source": [
    "# Triple Soft Matching\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Calculate precision, recall, and F1 score (soft matching)\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions (soft matching)\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted quadruples\n",
    "    predicted_positives = 0  # Predicted positives: Total number of quadruples predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of quadruples in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "        \n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            target_parts = None\n",
    "            \n",
    "            matched = False  # Flag to indicate if a matching target quadruple is found\n",
    "            \n",
    "            # Find matching target quadruple\n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # If the first two elements have similarity > 0.5 and the last element matches exactly, consider it a match\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    target_entity, target_speech, _, target_hate = target_parts  # Ignore the third element\n",
    "                    pred_entity, pred_speech, _, pred_hate = pred_parts  # Ignore the third element\n",
    "                    \n",
    "                    # Use soft matching for the first two elements\n",
    "                    similarity = SequenceMatcher(None, target_entity, pred_entity).ratio()\n",
    "                    similarity_speech = SequenceMatcher(None, target_speech, pred_speech).ratio()\n",
    "                    \n",
    "                    # If the first two elements have similarity > 0.5 and the last element matches exactly\n",
    "                    if similarity >= 0.5 and similarity_speech >= 0.5 and target_hate == pred_hate:\n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        matched = True  # Mark as matched\n",
    "                        break  # Exit inner loop and move to next predicted quadruple\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.2926\n",
      "Recall: 0.2855\n",
      "F1 Score: 0.2890\n"
     ]
    }
   ],
   "source": [
    "# Pair Hard Matching\n",
    "import json\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted pairs\n",
    "    predicted_positives = 0  # Predicted positives: Total number of pairs predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of pairs in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "\n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            \n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # Ensure the number of elements in quadruples is correct, then compare the first two elements\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    target_entity, target_speech, _, _ = target_parts\n",
    "                    pred_entity, pred_speech, _, _ = pred_parts\n",
    "                    \n",
    "                    # If the first two elements are identical, consider it a match\n",
    "                    if (target_entity == pred_entity and \n",
    "                        target_speech == pred_speech):\n",
    "                        \n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        break  # Exit inner loop once a matching pair is found\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5903\n",
      "Recall: 0.5759\n",
      "F1 Score: 0.5830\n"
     ]
    }
   ],
   "source": [
    "# Pair Soft Matching\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Calculate precision, recall, and F1 score (soft matching)\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions (soft matching)\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted doublets\n",
    "    predicted_positives = 0  # Predicted positives: Total number of doublets predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of doublets in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "        \n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            target_parts = None\n",
    "            \n",
    "            matched = False  # Flag to indicate if a matching target quadruple is found\n",
    "            \n",
    "            # Find matching target quadruple\n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # If the similarity of the first two elements exceeds 0.5, consider it a match\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    target_entity, target_speech, _, _ = target_parts  # Ignore the last two elements\n",
    "                    pred_entity, pred_speech, _, _ = pred_parts  # Ignore the last two elements\n",
    "                    \n",
    "                    # Use soft matching for the first two elements\n",
    "                    similarity = SequenceMatcher(None, target_entity, pred_entity).ratio()\n",
    "                    similarity_speech = SequenceMatcher(None, target_speech, pred_speech).ratio()\n",
    "                    \n",
    "                    # If the similarity of the first two elements is greater than 0.5, consider it a match\n",
    "                    if similarity >= 0.5 and similarity_speech >= 0.5:\n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        matched = True  # Mark as matched\n",
    "                        break  # Exit inner loop and move to next predicted quadruple\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.3462\n",
      "Recall: 0.3377\n",
      "F1 Score: 0.3419\n"
     ]
    }
   ],
   "source": [
    "# Single Element Hard Matching\n",
    "import json\n",
    "\n",
    "# Calculate precision, recall, and F1 score (hard matching)\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions (hard matching)\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted elements\n",
    "    predicted_positives = 0  # Predicted positives: Total number of elements predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of elements in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "        \n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            \n",
    "            # Find matching target quadruple\n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # If the second element of the predicted and target quadruples exactly match, consider it a match\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    _, target_speech, _, _ = target_parts  \n",
    "                    _, pred_speech, _, _ = pred_parts \n",
    "\n",
    "                    # If the second element exactly matches\n",
    "                    if target_speech == pred_speech:\n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        break  # Exit inner loop and move to next predicted quadruple\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7074\n",
      "Recall: 0.6900\n",
      "F1 Score: 0.6986\n"
     ]
    }
   ],
   "source": [
    "# Single Element Soft Matching\n",
    "import json\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Calculate precision, recall, and F1 score (soft matching)\n",
    "def calculate_metrics(predictions):\n",
    "    \"\"\"Calculate precision, recall, and F1 score for model predictions (soft matching)\"\"\"\n",
    "    \n",
    "    true_positives = 0  # True positives: Number of correctly predicted elements\n",
    "    predicted_positives = 0  # Predicted positives: Total number of elements predicted by the model\n",
    "    actual_positives = 0  # Actual positives: Total number of elements in the ground truth\n",
    "\n",
    "    for item in predictions:\n",
    "        # Split target and predicted quadruples\n",
    "        target_quadruples = item[\"output\"].split(\"[SEP]\")\n",
    "        prediction_quadruples = item[\"response\"].split(\"[SEP]\")\n",
    "\n",
    "        target_quadruples = [t.replace('[END]', '').strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.replace('[END]', '').strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        # Remove trailing whitespace from each quadruple to avoid comparison issues\n",
    "        target_quadruples = [t.strip() for t in target_quadruples if t.strip()]\n",
    "        prediction_quadruples = [p.strip() for p in prediction_quadruples if p.strip()]\n",
    "        \n",
    "        actual_positives += len(target_quadruples)  # Update total actual positives\n",
    "        predicted_positives += len(prediction_quadruples)  # Update total predicted positives\n",
    "        \n",
    "        # Compare each predicted quadruple with target quadruples\n",
    "        for pred in prediction_quadruples:\n",
    "            pred_parts = pred.split(\" | \")\n",
    "            target_parts = None\n",
    "            \n",
    "            matched = False  # Flag to indicate if a matching target quadruple is found\n",
    "            \n",
    "            # Find matching target quadruple\n",
    "            for t in target_quadruples:\n",
    "                target_parts = t.split(\" | \")\n",
    "                \n",
    "                # If the similarity of the first element exceeds 0.5, consider it a match\n",
    "                if len(target_parts) == 4 and len(pred_parts) == 4:\n",
    "                    _, target_speech, _, _ = target_parts  \n",
    "                    _, pred_speech, _, _ = pred_parts \n",
    "                    \n",
    "                    # Use soft matching for the first element\n",
    "                    similarity = SequenceMatcher(None, target_speech, pred_speech).ratio()\n",
    "                    # If the similarity of the first element is greater than 0.5, consider it a match\n",
    "                    if similarity >= 0.5:\n",
    "                        true_positives += 1\n",
    "                        target_quadruples.remove(t)  # Ensure each target quadruple is matched only once\n",
    "                        matched = True  # Mark as matched\n",
    "                        break  # Exit inner loop and move to next predicted quadruple\n",
    "        \n",
    "    # Calculate precision\n",
    "    precision = true_positives / predicted_positives if predicted_positives > 0 else 0\n",
    "    \n",
    "    # Calculate recall\n",
    "    recall = true_positives / actual_positives if actual_positives > 0 else 0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1_score\n",
    "\n",
    "# Load data\n",
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "# Main function\n",
    "def main(input_json_path):\n",
    "    # 1. Load data\n",
    "    data = load_data(input_json_path)\n",
    "\n",
    "    # 2. Calculate metrics\n",
    "    precision, recall, f1_score = calculate_metrics(data)\n",
    "    \n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1_score:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_json_path = \"your_test_file.json\"  # Path to your test file\n",
    "    main(input_json_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
